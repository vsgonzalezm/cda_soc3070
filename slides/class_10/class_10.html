<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Análisis de Datos Categóricos (SOC3070)</title>
    <meta charset="utf-8" />
    <meta name="author" content="  Mauricio Bucca  Profesor Asistente, Sociología UC" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="gentle-r.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Análisis de Datos Categóricos (SOC3070)
## Clase #10
### <br> Mauricio Bucca<br> Profesor Asistente, Sociología UC
### <a href="https://github.com/mebucca">github.com/mebucca</a>

---


class: inverse, center, middle

#Regresión Logística, interpretación

---
##Configuración

--

&lt;br&gt;

- Tenemos `\(y_{1}, \dots y_{n}\)` son `\(n\)` variables independientes con distribución `\(\text{Bernoulli}(p_{i})\)`


--

- `\(\mathbb{E}(y_{i} \mid x_{i1}, \dots,x_{ik}) = \mathbb{P}(y_{i}=1 \mid x_{i1}, \dots,x_{ik}) = p_{i}\)` 

&lt;br&gt;
--

donde, 


`$$\ln \frac{p_{i}}{1 - p_{i}} = \beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}$$`

---
##Configuración

&lt;br&gt;

- Tenemos `\(y_{1}, \dots y_{n}\)` son `\(n\)` variables independientes con distribución `\(\text{Bernoulli}(p_{i})\)`


- `\(\mathbb{E}(y_{i} \mid x_{i1}, \dots,x_{ik}) = \mathbb{P}(y_{i}=1 \mid x_{i1}, \dots,x_{ik}) = p_{i}\)` 

&lt;br&gt;

donde, 

`$$\underbrace{\ln \frac{p_{i}}{1 - p_{i}}}_{\text{Link logit}(p_{i})} = \beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}$$`
---
##Configuración


&lt;br&gt;

- Tenemos `\(y_{1}, \dots y_{n}\)` son `\(n\)` variables independientes con distribución `\(\text{Bernoulli}(p_{i})\)`



- `\(\mathbb{E}(y_{i} \mid x_{i1}, \dots,x_{ik}) = \mathbb{P}(y_{i}=1 \mid x_{i1}, \dots,x_{ik}) = p_{i}\)` 

&lt;br&gt;

donde, 

`$$\ln \frac{p_{i}}{1 - p_{i}} = \underbrace{\beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}}_{\text{Predictor lineal  } \eta_{i}}$$`
&lt;br&gt;
--

- Interpretación: ¿cuál es el significado de `\(\beta_{0},\beta_{1}, \dots, \beta_{k}\)`?

---
## Un ejemplo empírico



.pull-left[
Continuando con los datos de infidelidad, ajustaremos el siguiente modelo:

&lt;br&gt;
`$$\underbrace{\ln \frac{p_{i}}{ 1 - p_{i}}}_{\text{logit}(p_{i})}    = \beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i}$$`
&lt;br&gt;

donde:

- `\(p_{i} =\mathbb{P}(\text{everaffair}_{i}=1)\)`

- `\(\text{logit}(p_{i})\)` es el .bold[log odds] de tener un affair

- `\(p_{i}\)` y `\(\text{logit}(p_{i})\)` son una función género (male) y años de matrimonio (ym).

]

--
.pull-right[

```r
logit_affairs_sex_ym &lt;- 
  glm(everaffair_d ~ factor(sex) + ym, 
      family=binomial(link="logit"), 
      data=affairsdata)
summary(logit_affairs_sex_ym)
```

```
## 
## Call:
## glm(formula = everaffair_d ~ factor(sex) + ym, family = binomial(link = "logit"), 
##     data = affairsdata)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.9294  -0.8232  -0.6625  -0.5775   1.9197  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)     -1.71395    0.20633  -8.307  &lt; 2e-16 ***
## factor(sex)male  0.22157    0.19064   1.162 0.245139    
## ym               0.05843    0.01727   3.383 0.000718 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 675.38  on 600  degrees of freedom
## Residual deviance: 662.15  on 598  degrees of freedom
## AIC: 668.15
## 
## Number of Fisher Scoring iterations: 4
```
]

---
class: inverse, center, middle

## Efectos marginales sobre el logit 


---
## Efectos marginales sobre el logit 

Dado el siguiente modelo de regresión logística: 

`$$\text{logit}(p_{i}) = \ln \frac{p_{i}}{1 - p_{i}} = \beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}$$`
--

- El intercepto `\(\beta_{0}\)` corresponde al logit de la probabilidad de éxito cuando `\(x_{1} = \dots = x_{k} = 0\)`

--

- El efecto marginal de `\(\beta_{k}\)` sobre el logit de la probabilidad de éxito está dado por:


.pull-left[
.content-box-blue[
`$$\frac{\partial\text{logit}(p_{i})}{\partial x_{k}} = \beta_{k}$$`
]
]
.pull-right[
.content-box-yellow[
"Un cambio (infinitesimal) en `\(x_{k}\)` se traduce en un cambio en `\(\beta_{k}\)` unidades en el logit de p"
] 
]

--

¿Por qué?
--
 Asumamos que sólo la variable `\(x_{k}\)` cambia en una unidad, de `\(x_{k}=c\)` a `\(x_{k}=c+1\)`. Entonces:

--

`\begin{align}
  \frac{\Delta\text{logit}(p_{i}) }{\Delta x_{k}} &amp;= (\beta_{0} + \beta_{1}x_{1} +  \dots + \beta_{k}(c+1)) - (\beta_{0} + \beta_{1}x_{1}  \dots + \beta_{k}c)  \\ 
  &amp;=  \beta_{k}(c+1) - \beta_{k}c = \beta_{k}
\end{align}`


---
## Efectos marginales sobre el logit 

En nuestro ejemplo: `\(\ln \frac{p_{i}}{1 -p_{i}} = \beta_{0} + \beta_{1}*\text{male}_{i} + \beta_{2}*\text{ym}_{i}\)`

&lt;br&gt;

.pull-left[

```
##                    Estimate Std. Error
## (Intercept)     -1.71395429 0.20633183
## factor(sex)male  0.22157111 0.19064190
## ym               0.05842959 0.01727402
```
]
.pull-right[
![](class_10_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
]

---
## Efectos marginales sobre el logit 


.pull-left[

```
##                    Estimate Std. Error
## (Intercept)     -1.71395429 0.20633183
## factor(sex)male  0.22157111 0.19064190
## ym               0.05842959 0.01727402
```
]
.pull-right[
Si `male=1` y `ym=10`, entonces `logit(p)`=

```r
-1.714 + 0.222*1 + 0.05843*10
```

```
## [1] -0.9077
```

Si `male=1` y `ym=11`, entonces `logit(p)`=

```r
-1.714 + 0.222*1 + 0.05843*11
```

```
## [1] -0.84927
```

]

--

Por tanto, `\(\beta_{ym}\)`=

```r
((-1.714 + 0.222*1 + 0.05843*11)-(-1.714 + 0.222*1 + 0.05843*10))/(11 - 10)
```

```
## [1] 0.05843
```

---
class: inverse, center, middle

## Efectos multiplicativos sobre las odds de éxito 

---
## Efectos multiplicativos sobre las odds 

Dado el siguiente modelo de regresión logística: 

`$$\text{logit}(p_{i}) = \ln \frac{p_{i}}{1 - p_{i}} = \beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}$$`

&lt;br&gt;
--

exponenciando a ambos lados obtenemos 

`$$\frac{p_{i}}{1 - p_{i}} =  e^{\beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}}$$`

--

equivalentemente

.content-box-blue[
`$$\frac{p_{i}}{1 - p_{i}} =  e^{\beta_{0}} \cdot e^{\beta_{1} x_{i1}}  \dots e^{\beta_{k} x_{ik}}$$`
]

---
## Efectos multiplicativos sobre las odds 

`$$\frac{p_{i}}{1 - p_{i}} =  e^{\beta_{0}} \cdot e^{\beta_{1} x_{i1}}  \dots e^{\beta_{k} x_{ik}}$$`
--

Examinando esta ecuación observamos que cuando `\(x_1 = \dots = x_k = 0\)`, 


&lt;br&gt;


`$$\frac{p_{i}}{1 - p_{i}}=  e^{\beta_{0}}$$`
Es decir, cuando `\(x_1 = \dots = x_k = 0\)` las odds de éxito están dadas por `\(e^{\beta_{0}}\)`.


&lt;br&gt;
--

Generalizando,  observamos que cuando `\(x_1 = c_1  \dots = x_k = c_k\)`,  las odds de éxito están dadas por

&lt;br&gt;

`$$\frac{p_{i}}{1 - p_{i}} =  e^{\beta_{0}} \cdot e^{\beta_{1} c_{1}}  \dots e^{\beta_{k} c_{k}}$$`


---
## Efectos multiplicativos sobre las odds: odds ratios

Considera la situación en que `\(i\)` y `\(j\)` son dos observaciones con `\(x_{k}=c\)` y `\(x_{k}=c+1\)`, respectivamente. El resto de las covariables toman valores idénticos. 
--
 Las odds de éxito para cada caso son:


- `\(p_{i}/(1 - p_{i}) = e^{\beta_{0}} \cdot e^{\beta_{1} x_{i1}}  \dots (e^{\beta_{k}})^{c}\)`

- `\(p_{j}/(1 - p_{j}) = e^{\beta_{0}} \cdot e^{\beta_{1} x_{i1}}  \dots (e^{\beta_{k}})^{c+1}\)`


&lt;br&gt;
--

El ratio de las odd de éxito entre `\(j\)` e `\(i\)` está dado por:

`\begin{align}
\frac{p_{j}/(1 - p_{j})}{p_{i}/(1 - p_{i})} &amp;= \frac{e^{\beta_{0}} \cdot e^{\beta_{1} x_{i1}}  \dots (e^{\beta_{k}})^{c+1}}{e^{\beta_{0}} \cdot e^{\beta_{1} x_{i1}}  \dots (e^{\beta_{k}})^{c}} \\ \\
&amp;= e^{\beta_{k}}
\end{align}`

En otras palabras, manteniendo otros factores constantes, `\(e^{\beta_{k}}\)` representa la odds ratio entre el caso con `\(x_{k}\)` aumentado en una unidad, y el caso con `\(x_{k}\)` en un nivel basal dado. 


---
## Efectos multiplicativos sobre las odds 


.content-box-yellow[
"Un cambio en `\(\Delta\)` unidades de `\(x_{k}\)` multiplica las las odds de éxito por `\(e^{\Delta \beta_{k}}\)`"
] 

&lt;br&gt;
.bold[Propiedades]:

--

- `\(e^{\beta_{k}}\)` está restringido al rango `\([0,\infty+)\)`. Es una constante que "comprime" o amplifica las odds de éxito.

--

- Si `\(\beta_{k} &lt; 0  \to  (0 &lt; e^{\beta_{k}} &lt; 1)\)`. Es decir, un aumento en `\(x_{k}\)` está asociado con una reducción (multiplicativa) de las odds de éxito.

--

- Si `\(\beta_{k} = 0  \to  (e^{\beta_{k}} =1)\)`. Es decir, un cambio en `\(x_{k}\)` está asociado a un cambio nulo en las odds de éxito.

--

- Si `\(\beta_{k} &gt; 0  \to  (e^{\beta_{k}} &gt; 1)\)`. Es decir, un aumento en `\(x_{k}\)` está asociado a aumento (multiplicativo) en de las odds de éxito.

---
## Efectos marginales sobre las odds 

Dado el siguiente modelo: 
    
`$$\frac{p_{i}}{1 - p_{i}} =  e^{\beta_{0}} \cdot e^{\beta_{1} x_{1}}  \dots e^{\beta_{k} x_{k}}$$`
&lt;br&gt;
--
      
      
- El efecto marginal de `\(\beta_{k}\)` sobre las odds de éxito está dado por:
      
      
.content-box-blue[
`$$\frac{\partial \{ p_{i}/(1 - p_{i}) \} }{\partial x_{k}} = \beta_{k}  \cdot e^{\beta_{0}} \cdot  e^{\beta_{1} x_{1}} \cdot \cdot \cdot e^{\beta_{k} x_{k}} = \beta_{k} \cdot p_{i}/(1 - p_{i})$$`
]
    
--
      
"Un cambio (infinitesimal) en `\(x_{k}\)` se traduce en un cambio en `\(\beta_{k} \cdot p_{i}/(1 - p_{i})\)` unidades en las odds de éxito"

--

- El efecto de `\(x_{k}\)` sobre las odds depende del valor de las odds, que a su vez depende de `\(x_{k}\)` y todas las covariables.

---
## Efectos marginales sobre las odds 

En nuestro ejemplo: `\(\ln \frac{p_{i}}{1 -p_{i}} = \beta_{0} + \beta_{1}*\text{male}_{i} + \beta_{2}*\text{ym}_{i}\)`, por tanto:
  
  
.pull-left[
  `\(\frac{p_{i}}{1 -p_{i}} = e^{\beta_{0}} \cdot  e^{\beta_{1}*\text{male}_{i}} \cdot e^{\beta_{2}*\text{ym}_{i}}\)`
      

```r
# coeffs
summary(logit_affairs_sex_ym)$coefficients[,c(1,2)]
```

```
##                    Estimate Std. Error
## (Intercept)     -1.71395429 0.20633183
## factor(sex)male  0.22157111 0.19064190
## ym               0.05842959 0.01727402
```

```r
# exp(coeffs)
exp(summary(logit_affairs_sex_ym)$coefficients[,c(1)])
```

```
##     (Intercept) factor(sex)male              ym 
##        0.180152        1.248036        1.060170
```
    
]

--
  
.pull-right[
  ![](class_10_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;
]

---
## Efectos marginales sobre las odds 


.pull-left[

```
##                        coef exp.coef.
## (Intercept)     -1.71395429  0.180152
## factor(sex)male  0.22157111  1.248036
## ym               0.05842959  1.060170
```
]
.pull-right[
Si `male=1` y `ym=10`, entonces las odds de tener un affair =

```r
exp(-1.714 + 0.222*1 + 0.05843*10)
```

```
## [1] 0.4034511
```

Si `male=1` y `ym=11`, entonces las odds de tener un affair =

```r
exp(-1.714 + 0.222*1 + 0.05843*11)
```

```
## [1] 0.4277271
```

]

--

Por tanto, `\(e^{\beta_{ym}}\)`=

```r
exp(-1.714 + 0.222*1 + 0.05843*11)/exp(-1.714 + 0.222*1 + 0.05843*10)
```

```
## [1] 1.060171
```
 
---
class: inverse, center, middle

## Efectos marginales sobre la probabilidad de éxito 


---
## Efectos marginales sobre la probabilidad de éxito

Dado el siguiente modelo de regresión logística: 

`$$\ln \frac{p_{i}}{1 - p_{i}} = \beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}$$`

&lt;br&gt;
--
Queremos saber el .bold[efecto marginal] de los predictores sobre la .bold[probabilidad] de éxito. Formalmente
--
`$$\frac{\partial p_{i}}{\partial x_{k}}$$`
Paso a paso...


&lt;br&gt;
--

- .bold[Paso 1]: reexpresar la ecuación de regresión como

&lt;br&gt;

`$$\ln(p_{i}) - \ln(1-p_{i}) = \beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}$$`


---
## Efectos marginales sobre la probabilidad de éxito


- .bold[Paso 1]: reexpresar la ecuación de regresión como


`$$\ln(p_{i}) - \ln(1-p_{i}) = \beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}$$`

&lt;br&gt;
--

- .bold[Paso 2]: usando diferenciación implícita y tomando derivada con respecto a `\(x_{k}\)` en ambos lados, obtenemos:

`$$\frac{\partial p_{i} }{\partial x_{k}} \frac{1}{p_{i}} + \frac{\partial p_{i} }{\partial x_{k}} \frac{1}{(1 - p_{i})} = \beta_{k}$$`
&lt;br&gt;
--

- .bold[Paso 3]: re-agrupando:

`$$\frac{\partial p_{i} }{\partial x_{k}} \frac{1}{p_{i}(1 - p_{i})}= \beta_{k}$$`

---
## Efectos marginales sobre la probabilidad de éxito


- .bold[Paso 3]: re-agrupando:

`$$\frac{\partial p_{i} }{\partial x_{k}} \frac{1}{p_{i}(1 - p_{i})}= \beta_{k}$$`

&lt;br&gt;
--

- .bold[Paso 4]: re-ordebando los términos obtenemos el efecto marginal que buscamos:

.content-box-blue[
`$$\frac{\partial p_{i}}{\partial x_{k}}= \beta_{k} \cdot p_{i}(1 - p_{i})$$`
]

--

recordar que ...
  `$$p_{i} = \frac{1}{1 + e^{-(\beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik})}}$$`

---
## Efectos marginales sobre la probabilidad de éxito

- .bold[Paso 5]: reemplazando,

`$$\frac{\partial p_{i}}{\partial x_{k}}= \beta_{k} \cdot \Bigg(\frac{1}{1 + e^{-(\beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}})}\Bigg) \Bigg(1 - \frac{1}{1 + e^{-(\beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik})}}\Bigg)$$`

&lt;br&gt;
--

Corolario:

--

- Dado que `\(p_{i}(1-p_{i})\)` es estrictamente positivo,
 - `\(\beta_{k}&gt;0\)` indica que variable `\(x_{k}\)` tienen un efecto positivo sobre la probabilidad de éxito
 - `\(\beta_{k}&lt;0\)` indica que `\(x_{k}\)` tiene un efecto negativo.

&lt;br&gt;
--

- El .bold[efecto marginal] de `\(x_{k}\)` no depende sólo de `\(\beta_{k}\)` sino varía dependiendo del valor de `\(x_{k}\)` y del valor de todas las otras covariables.


---
## Efectos marginales sobre la probabilidad de éxito

`$$\frac{\partial p_{i}}{\partial x_{k}}= \beta_{k} \cdot \Bigg(\frac{1}{1 + e^{-(\beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}})}\Bigg) \Bigg(1 - \frac{1}{1 + e^{-(\beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik})}}\Bigg)$$`

&lt;br&gt;
--

Corolario, 

--

- A medida que la `\(p_{i}\)` se aproxima a 0, `\(\frac{\partial p_{i}}{\partial x_{k}}\)` tiende a 0.

- A medida que la `\(p_{i}\)` se aproxima a 1, `\(\frac{\partial p_{i}}{\partial x_{k}}\)` tiende a 0.

- A medida que la `\(p_{i}\)` se acerca a 0.5, `\(\frac{\partial p_{i}}{\partial x_{k}}\)` tiende a `\(\beta_{k}/4\)`.


---
## Efectos marginales sobre la probabilidad de éxito

En nuestro ejemplo: `\(\ln \frac{p_{i}}{1 -p_{i}} = \beta_{0} + \beta_{1}*\text{male}_{i} + \beta_{2}*\text{ym}_{i}\)`, por tanto:
`$$p_{i} = \frac{1}{1 + e^{-(\beta_{0} + \beta_{1}*\text{male}_{i} + \beta_{2}*\text{ym}_{i})} }$$`

.pull-left[

```
##                    Estimate Std. Error
## (Intercept)     -1.71395429 0.20633183
## factor(sex)male  0.22157111 0.19064190
## ym               0.05842959 0.01727402
```
]
.pull-right[
![](class_10_files/figure-html/unnamed-chunk-16-1.png)&lt;!-- --&gt;
]

---
## Efectos marginales sobre la probabilidad de éxito

.pull-left[
`$$p_{i} = \frac{1}{1 + e^{-(\beta_{0} + \beta_{1}*\text{male}_{i} + \beta_{2}*\text{ym}_{i})}}$$`

![](class_10_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;
]

--

.pull-right[
`$$\frac{\partial p_{i}}{\partial \text{ym} }= \beta_{\text{ym}} \cdot p_{i}(1 - p_{i})$$`

![](class_10_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;
]
---
## Efectos marginales sobre la probabilidad de éxito

- Efectos marginales son _esencialmente_ heterogeneos. No hay un efecto sino muchos. 

--

- Heterogeneidad crece con la complejidad del modelo: número de predictores, interacciones, etc. 

--

- En la práctica, muchas veces queremos UN número que resuma el efecto marginal. 

&lt;br&gt;
--
.pull-left[
![For god sakes just give me the damn number](https://i.makeagif.com/media/8-29-2018/ior4IF.gif)
]

--

Cantidades de interes:
.pull-right[

* Average Marginal Effects (AME)

* Marginal Effects at the Mean (MEM)

* Marginal Effects at Representative Values (MER)

]

---
## Efectos marginales sobre la probabilidad de éxito: AME

.bold[AME]: Efecto marginal promedio (en muestra)

.pull-left[
En `Stata`
![ame](ame.png)
]

--

.pull-right[
En `R`

```r
library("margins")
summary(
  margins(logit_affairs_sex_ym)
  )
```

```
##   factor    AME     SE      z      p   lower  upper
##  sexmale 0.0407 0.0351 1.1615 0.2454 -0.0280 0.1094
##       ym 0.0107 0.0031 3.4740 0.0005  0.0047 0.0167
```
]

&lt;br&gt;
--

¿Cómo lo calculamos?

---
## Efectos marginales sobre la probabilidad de éxito: AME


```r
summary(margins(logit_affairs_sex_ym))
```

```
##   factor    AME     SE      z      p   lower  upper
##  sexmale 0.0407 0.0351 1.1615 0.2454 -0.0280 0.1094
##       ym 0.0107 0.0031 3.4740 0.0005  0.0047 0.0167
```


&lt;br&gt;
--

¿Cómo se calcula el AME de "years of marriage"?

--


```r
beta_ym = logit_affairs_sex_ym$coefficients[3] # coeficiente ym 
p_hat &lt;- predict(logit_affairs_sex_ym, type="response") # prob predichas cada obs.
me_ym = beta_ym*p_hat*(1-p_hat) # efector marginal para cada obs.
```

--

.pull-left[
![](class_10_files/figure-html/unnamed-chunk-22-1.png)&lt;!-- --&gt;
]

.pull-left[

```r
ame = round(mean(me_ym),4)
print(paste0("AME Years of Marriage: ", ame))
```

```
## [1] "AME Years of Marriage: 0.0107"
```
]

---
## Efectos marginales sobre la probabilidad de éxito: AME

¿Y si no conocemos la expresión analítica?
--
 .bold[Aproximación numérica]:
--

`$$\frac{\partial p_{i}}{\partial x_{k}} \approx  \frac{p_{i}(x_{1}, \dots ,x_{k} = c + \delta) - p_{i}(x_{1}, \dots ,x_{k} = c )}{\delta}$$`
&lt;br&gt;
--


```r
p_hat &lt;- predict(logit_affairs_sex_ym, type="response") # prob predichas cada obs.

delta = 0.01 # cantidad cambio
affairsdata_delta &lt;- affairsdata %&gt;% mutate(ym = ym + delta) # cambio marginal en ym
# probabilidad predicha con ym aumentado marginalmente
p_hat_delta &lt;- predict(logit_affairs_sex_ym, newdata=affairsdata_delta ,type="response") 

me_ym_approx &lt;- (p_hat_delta - p_hat)/delta # approx. numerica marginal effect.

# average marginal effect
round(mean(me_ym_approx),4)
```

```
## [1] 0.0107
```

---
## Efectos marginales sobre la probabilidad de éxito: MEM

.bold[MEM]: Efecto marginal al valor promedio (en muestra)

En `Stata`

.pull-left[
![mem](mem.png)
]

--

.pull-right[

![ah](http://25.media.tumblr.com/tumblr_lx16y1gdGm1qls3mfo1_500.gif)


]

---
## Efectos marginales sobre la probabilidad de éxito: MEM

--

- ¿Cuál media?
  - a) ¿La media de "years of marriage" para cada género por separado?
  - b) ¿La media global de "years of marriage" por cada género por separado?
  - c) ¿La media global de "years of marriage" y la media género (como var. continua)?

--

Depende de que lo que queremos.

--

Implentamos opción (c) en `R`

```r
affairsdata &lt;- affairsdata %&gt;% mutate(male = 1*(sex=="male"))
logit_affairs_sex_ym2 &lt;- glm(everaffair_d ~ male + ym, family=binomial(link="logit"), 
                             data=affairsdata)

mean_male = mean(affairsdata$male)
mean_ym = mean(affairsdata$ym)

summary(margins(logit_affairs_sex_ym2, at=list(male=mean_male, ym=mean_ym)))
```

```
##  factor   male     ym    AME     SE      z      p   lower  upper
##    male 0.4759 8.1777 0.0409 0.0351 1.1640 0.2444 -0.0280 0.1097
##      ym 0.4759 8.1777 0.0108 0.0031 3.4270 0.0006  0.0046 0.0169
```

--

¿Cómo lo calculamos?

---
## Efectos marginales sobre la probabilidad de éxito: MEM

Solución analística, usando 
`$$\frac{\partial p_{i}}{\partial \text{ym} }= \beta_{\text{ym}} \cdot p_{i}(1 - p_{i})$$`

--


```r
beta_ym = logit_affairs_sex_ym$coefficients[3] # coeficiente ym 
grid &lt;- affairsdata %&gt;% data_grid(male=mean_male, ym=mean_ym, .model=logit_affairs_sex_ym2); grid
```

```
## # A tibble: 1 x 2
##    male    ym
##   &lt;dbl&gt; &lt;dbl&gt;
## 1 0.476  8.18
```

```r
p_hat &lt;- predict(logit_affairs_sex_ym2, newdata=grid, type="response") # prob predichas 

mem_ym = beta_ym*p_hat*(1-p_hat); round(mem_ym,4) # efecto marginal 
```

```
##     ym 
## 0.0108
```

---
## Efectos marginales sobre la probabilidad de éxito: MEM

Aproximación numérica, usando: 
`$$\frac{\partial p_{i}}{\partial x_{k}} \approx  \frac{p_{i}(x_{1}, \dots ,x_{k} = c + \delta) - p_{i}(x_{1}, \dots ,x_{k} = c )}{\delta}$$`
&lt;br&gt;
--


```r
delta = 0.01 # cantidad cambio

grid &lt;- affairsdata %&gt;% data_grid(male=mean_male, ym=mean_ym, .model=logit_affairs_sex_ym2)
grid_delta &lt;- affairsdata %&gt;% data_grid(male=mean_male, ym=mean_ym + delta, .model=logit_affairs_sex_ym2)

p_hat &lt;- predict(logit_affairs_sex_ym2, newdata=grid, type="response") # prob predichas 
p_hat_delta &lt;- predict(logit_affairs_sex_ym2, newdata=grid_delta, type="response") # prob predichas 

mem_ym_approx = (p_hat_delta - p_hat)/delta
round(mem_ym_approx,4) # efecto marginal 
```

```
##      1 
## 0.0108
```

---
## Efectos marginales sobre la probabilidad de éxito: MER

Una versión más general de MEM es calcular los efectos marginales para "valores representativos". 

.pull-left[
En `Stata`
![ame](mer.png)
]

--

.pull-right[
En `R`

```r
margins(logit_affairs_sex_ym, 
at = list(sex = c("male", "female"), 
ym = quantile(affairsdata$ym, 
              p=c(0.25,0.5,0.75)) ))
```

```
## Average marginal effects at specified values
```

```
## glm(formula = everaffair_d ~ factor(sex) + ym, family = binomial(link = "logit"),     data = affairsdata)
```

```
##  at(sex) at(ym)       ym sexfemale
##     male      4 0.010066  -0.03581
##   female      4 0.008824  -0.03581
##     male      7 0.011039  -0.03953
##   female      7 0.009806  -0.03953
##     male     15 0.013305  -0.04865
##   female     15 0.012318  -0.04865
```
]

--

¿Cómo lo calculamos?

---
## Efectos marginales sobre la probabilidad de éxito: MER

Solución analística, usando 
`$$\frac{\partial p_{i}}{\partial \text{ym} }= \beta_{\text{ym}} \cdot p_{i}(1 - p_{i})$$`

--


```r
beta_ym = logit_affairs_sex_ym$coefficients[3] # coeficiente ym 
grid &lt;- affairsdata %&gt;% data_grid(sex, ym=quantile(affairsdata$ym, p=c(0.25,0.5,0.75)), .model=logit_affairs_sex_ym)
grid &lt;- grid %&gt;% mutate(p_hat =predict(logit_affairs_sex_ym, newdata=grid, type="response")) # prob predichas
grid &lt;- grid %&gt;% mutate(mer_ym = beta_ym*p_hat*(1-p_hat)); grid  # efecto marginal
```

```
## # A tibble: 6 x 4
##   sex       ym p_hat  mer_ym
##   &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
## 1 female     4 0.185 0.00882
## 2 female     7 0.213 0.00981
## 3 female    15 0.302 0.0123 
## 4 male       4 0.221 0.0101 
## 5 male       7 0.253 0.0110 
## 6 male      15 0.351 0.0133
```


---
## Efectos marginales sobre la probabilidad de éxito: MER

Aproximación numérica, usando: 
`$$\frac{\partial p_{i}}{\partial x_{k}} \approx  \frac{p_{i}(x_{1}, \dots ,x_{k} = c + \delta) - p_{i}(x_{1}, \dots ,x_{k} = c )}{\delta}$$`

--

```r
delta = 0.01 # cantidad cambio
grid &lt;- affairsdata %&gt;% data_grid(sex, ym=quantile(affairsdata$ym, p=c(0.25,0.5,0.75)), .model=logit_affairs_sex_ym)
grid_delta &lt;- affairsdata %&gt;% data_grid(sex, ym=quantile(affairsdata$ym, p=c(0.25,0.5,0.75)) + delta, .model=logit_affairs_sex_ym)
p_hat &lt;- predict(logit_affairs_sex_ym, newdata=grid, type="response") # prob predichas
p_hat_delta &lt;- predict(logit_affairs_sex_ym, newdata=grid_delta, type="response") # prob predichas
grid &lt;- grid %&gt;% mutate(mem_ym_approx = (p_hat_delta - p_hat)/delta); grid # efecto marginal
```

```
## # A tibble: 6 x 3
##   sex       ym mem_ym_approx
##   &lt;fct&gt;  &lt;dbl&gt;         &lt;dbl&gt;
## 1 female     4       0.00883
## 2 female     7       0.00981
## 3 female    15       0.0123 
## 4 male       4       0.0101 
## 5 male       7       0.0110 
## 6 male      15       0.0133
```

---
class: inverse, center, middle

.huge[
**Hasta la próxima clase. Gracias!**
]

&lt;br&gt;
Mauricio Bucca &lt;br&gt;
https://mebucca.github.io/ &lt;br&gt;
github.com/mebucca
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
